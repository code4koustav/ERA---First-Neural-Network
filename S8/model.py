# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RlaLXJf8DZQDGI3xR2iGlWplkWkpWlJq
"""

# import all necessery library

from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision import datasets, transforms
import numpy as np

# Model with Batch normalization



class BatchNormalization(nn.Module):
    def __init__(self,DROPOUT_VALUE = 0.04):
        super(BatchNormalization, self).__init__()
        # CONVOLUTION BLOCK 1
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(8),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 2
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 1
        self.trans1 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 3
        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 4
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 5
        self.conv5 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 2
        self.trans2 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 6
        self.conv6 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 7
        self.conv7 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 8
        self.conv8 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # OUTPUT BLOCK
        self.gap = nn.Sequential(
            nn.AvgPool2d(kernel_size=9)
        )

         # CONVOLUTION BLOCK 9
        self.conv9 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.trans1(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.trans2(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.conv8(x)
        x = self.gap(x)
        x = self.conv9(x)

        x = x.view(-1, 10)
        return F.log_softmax(x, dim=-1)
    
# model for group normalization

class GroupNormalization(nn.Module):
    def __init__(self,DROPOUT_VALUE = 0.04):
        super(GroupNormalization, self).__init__()
        # CONVOLUTION BLOCK 1
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,8),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 2
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 1
        self.trans1 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 3
        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 4
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 5
        self.conv5 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 2
        self.trans2 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 6
        self.conv6 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 7
        self.conv7 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 8
        self.conv8 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(4,64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # OUTPUT BLOCK
        self.gap = nn.Sequential(
            nn.AvgPool2d(kernel_size=9)
        )

         # CONVOLUTION BLOCK 9
        self.conv9 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.trans1(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.trans2(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.conv8(x)
        x = self.gap(x)
        x = self.conv9(x)

        x = x.view(-1, 10)
        return F.log_softmax(x, dim=-1)


# Model for Layer Normalization

class LayerNormalization(nn.Module):
    def __init__(self,DROPOUT_VALUE = 0.04):
        super(LayerNormalization, self).__init__()
        # CONVOLUTION BLOCK 1
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,8),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 2
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 1
        self.trans1 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 3
        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 4
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 5
        self.conv5 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # TRANSITION BLOCK 2
        self.trans2 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=8, kernel_size=(1, 1), padding=1, bias=False),
            nn.MaxPool2d(2, 2)
        )

        # CONVOLUTION BLOCK 6
        self.conv6 = nn.Sequential(
            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,16),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 7
        self.conv7 = nn.Sequential(
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,32),
            nn.Dropout(DROPOUT_VALUE)
        )

        # CONVOLUTION BLOCK 8
        self.conv8 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),
            nn.ReLU(),
            nn.GroupNorm(1,64),
            nn.Dropout(DROPOUT_VALUE)
        )

        # OUTPUT BLOCK
        self.gap = nn.Sequential(
            nn.AvgPool2d(kernel_size=9)
        )

         # CONVOLUTION BLOCK 9
        self.conv9 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.trans1(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.trans2(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.conv8(x)
        x = self.gap(x)
        x = self.conv9(x)

        x = x.view(-1, 10)
        return F.log_softmax(x, dim=-1)


# calling main function

def CNN_model(model_type):
    if model_type == 'BN':
        model = BatchNormalization()
    elif model_type == 'GN':
        model = GroupNormalization()
    elif model_type == 'LN':
        model = LayerNormalization()
    else:
        raise Exception("Invalid Normalization: model_type should be 'BN' or 'GN' or 'LN'")
    
    return model

